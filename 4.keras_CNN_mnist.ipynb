# 匯入必要的套件
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten

# ==============================
# 建立 CNN 模型
# ==============================
model = Sequential()

# 第 1 層：卷積層 (Convolution Layer)
# filters=16 ：代表 16 個卷積核（學習 16 種不同特徵）
# kernel_size=(5,5)：每個卷積核大小為 5x5
# input_shape=(28,28,1)：輸入為 28x28 的灰階圖片（1 表示通道數）
# activation='relu'：使用 ReLU 激活函數，能增加非線性特徵
model.add(Conv2D(filters=16, kernel_size=(5, 5), input_shape=(28, 28, 1), activation='relu'))

# 第 2 層：最大池化層 (Max Pooling)
# pool_size=(2,2)：每次取 2x2 的最大值，讓影像縮小一半
model.add(MaxPooling2D(pool_size=(2, 2)))

# 第二組卷積與池化層可選擇性加入（提升準確率但增加計算量）
# model.add(Conv2D(filters=36, kernel_size=(5, 5), activation='relu'))
# model.add(MaxPooling2D(pool_size=(2, 2)))

# 將多維特徵圖攤平成一維向量
model.add(Flatten())

# 輸出層 (Dense)
# 共有 10 個輸出神經元，對應數字 0~9
# 使用 softmax 將輸出轉為 10 個類別的機率分佈
model.add(Dense(10, activation='softmax'))

# 顯示模型架構摘要
model.summary()

# ==============================
# 編譯模型 (Compile)
# ==============================
# optimizer='rmsprop' ：使用 RMSprop 優化器（自動調整學習率）
# loss='categorical_crossentropy' ：多類別交叉熵損失函數（對應 one-hot 標籤）
# metrics=['accuracy'] ：使用準確率作為評估指標
model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

# ==============================
# 載入 MNIST 資料集
# ==============================
mnist = keras.datasets.mnist
(train_data, train_label), (test_data, test_label) = mnist.load_data()

# 保留原始測試標籤以便後續做混淆矩陣
test_label_original = test_label

# 將標籤轉為 one-hot 編碼
# 例如數字「3」會轉為 [0,0,0,1,0,0,0,0,0,0]
train_label = keras.utils.to_categorical(train_label)
test_label = keras.utils.to_categorical(test_label)

# ==============================
# 資料預處理：將影像轉為 CNN 可用格式
# ==============================
# 原始資料 shape 為 (60000, 28, 28)
# 需加上通道數維度 (28, 28, 1)
train_data = train_data.reshape(-1, 28, 28, 1).astype('float32') / 255
test_data = test_data.reshape(-1, 28, 28, 1).astype('float32') / 255

# ==============================
# 模型訓練 (Training)
# ==============================
# epochs=10 ：訓練 10 個週期
# batch_size=512 ：每次使用 512 筆資料更新權重
train_history = model.fit(train_data, train_label, epochs=10, batch_size=512)

# ==============================
# 模型評估 (Evaluation)
# ==============================
score = model.evaluate(test_data, test_label)
print("測試準確率：", score[1])
# Output: 約 0.9774 (97.74%)

# ==============================
# 繪製訓練過程圖表
# ==============================
import matplotlib.pyplot as plt
import numpy as np

def show_train_history(train_history, train, validation):
    plt.plot(train_history.history[train])
    plt.plot(train_history.history[validation])
    plt.title('Train History')
    plt.ylabel(train)
    plt.xlabel('Epoch')
    plt.legend(['train', 'validation'], loc='center right')
    plt.show()

# 繪出準確率變化
show_train_history(train_history, 'accuracy', 'accuracy')

# 繪出損失變化
show_train_history(train_history, 'loss', 'loss')

# ==============================
# 混淆矩陣 (Confusion Matrix)
# ==============================
import pandas as pd

# 使用模型預測測試資料
prediction = model.predict(test_data)

# 取出預測類別（機率最高者）
prediction_label = np.argmax(prediction, axis=1)

# 顯示測試標籤 shape (10000, 10)
print(test_label.shape)

# 製作混淆矩陣表
# 列：實際標籤 ； 欄：模型預測結果
pd.crosstab(test_label_original, prediction_label, rownames=['label'], colnames=['predict'])
